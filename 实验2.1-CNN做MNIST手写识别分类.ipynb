{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内容一：利用CNN对pytorch内置数据集MNIST进行手写识别分类\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  实验步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实验前导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的包\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as tud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义dataset\n",
    "mnist_train_data= datasets.MNIST(\"./mnist_data\",train=True,download=True,transform=transforms.ToTensor())\n",
    "# 定义dataloader\n",
    "mnist_train_dataloader=tud.DataLoader(mnist_train_data,batch_size=64,shuffle=True)#DataLoader类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_data= datasets.MNIST(\"./mnist_data\",train=False,download=True,transform=transforms.ToTensor())\n",
    "mnist_test_dataloader=tud.DataLoader(mnist_test_data,batch_size=64,shuffle=True)#DataLoader类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "train_data: torch.Size([10000, 28, 28])\n",
      "train_data: torch.Size([60000, 28, 28])\n",
      "train_labels: torch.Size([60000])\n",
      "(<PIL.Image.Image image mode=L size=28x28 at 0x19B7BE2DE48>, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28038\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\28038\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\28038\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x19B7BE2DE48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_data_numpy=datasets.MNIST(\"./mnist_data\",train=True,download=False)\n",
    "# 查看数据\n",
    "print(len(mnist_test_dataloader.dataset))\n",
    "print(\"train_data:\", mnist_test_data.test_data.size())\n",
    "print(\"train_data:\", mnist_train_data.train_data.size())# datdaset类中要分mnist_train_data.train_data.size和mnist_train_data.train_labels\n",
    "print(\"train_labels:\", mnist_train_data.train_labels.size())\n",
    "# 查看原本的数据集形式及标签\n",
    "print(mnist_train_data_numpy[0])\n",
    "mnist_train_data_numpy[0][0]# 查看标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 配置网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义简单的卷积神经网络 输入的size:(1*28*28)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()#复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数\n",
    "        self.conv1=nn.Conv2d(1,20,5,1)# 输入为图像（1个频道，即灰度图）,输出为 20张特征图（通道数）, 卷积核为5x5正方形，【（28-5）/1】+1=24\n",
    "        self.conv2=nn.Conv2d(20,50,5,1)# 50个5*5的卷积核，输出为 50张特征图（通道数）步长为1   【（24-5）/1】+1=20\n",
    "        self.fc1=nn.Linear(4*4*50,500)# 将50*4*4个节点通过线性函数连接到500个节点上\n",
    "        self.fc2=nn.Linear(500,10)# 将500个节点通过线性函数连接到10个节点上，也就是分10类\n",
    "# 定义向前传播\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.conv1(x))# 结果20*24*24\n",
    "        x=F.max_pool2d(x,2,2)# 使用2x2的窗口进行最大池化Max pooling，然后更新到x，结果20*12*12   12-5+1=8 \n",
    "        x=F.relu(self.conv2(x))# 结果50*8*8\n",
    "        x=F.max_pool2d(x,2,2)# 结果50*4*4\n",
    "        x=x.view(-1,4*4*50)#view函数将张量x变形成一维的向量形式，总特征数并不改变，为接下来的全连接作准备\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 实例化模型\n",
    "mnist_model=Net()\n",
    "mnist_model = mnist_model.cuda()\n",
    "# 定义损失函数\n",
    "Loss_fn= nn.CrossEntropyLoss()\n",
    "# 定义优化策略\n",
    "optimizer=optim.SGD(mnist_model.parameters(),lr=0.01,momentum=0.5)   # Net.parameters()要和上面的Net一致\n",
    "### 易错使用Net.parametres()一定要进行实例化，就是先对模型实例化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义训练和测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练网络函数\n",
    "def Train(model,train_dataloader,Loss_fn,optimizer,epoch):\n",
    "    model.train()#使用BatchNormalization 和 Dropout \n",
    "    for idx,(img,label) in enumerate(train_dataloader):\n",
    "        img,label=img.cuda(),label.cuda()\n",
    "        output=model(img)# \n",
    "        loss=Loss_fn(output,label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx%100==0:\n",
    "            print(\"train_epoch:{}，iteration：{}，loss:{:.5f},\".format(epoch,idx,loss.item()))# :.5f保留五位\n",
    "    return model# 方便取最优模型\n",
    "## 定义测试网络的函数        \n",
    "def Test(model,test_dataloader,Loss_fn):\n",
    "    model.eval() #不使用BatchNormalization 和 Dropout \n",
    "    total_loss=0. #0后面有个点，浮点型，才可以让最后结果不为零\n",
    "    total_accnum=0.\n",
    "    with torch.no_grad():# 不需要反向求导进行优化，所以不用梯度\n",
    "        for idx,(img,label) in enumerate(test_dataloader):\n",
    "            img,label=img.cuda(),label.cuda()\n",
    "            output=model(img)# output 64*10\n",
    "            loss=Loss_fn(output,label)\n",
    "            pred= output.argmax(dim=1)#torch.argmax()返回指定维度最大值的序号 特别的在dim=0表示二维中的列，dim=1在二维矩阵中表示行\n",
    "            # 测试需要计算准确率\n",
    "            total_loss += loss\n",
    "            total_accnum += pred.eq(label).sum()\n",
    "            # total_accnum += (pred==label).sum()\n",
    "            \n",
    "    total_loss/=len(test_dataloader.dataset)\n",
    "    acc=total_accnum/len(test_dataloader.dataset)\n",
    "    print(\"test_loss:{:.5f}，准确率:{:.5f}\".format(total_loss,acc))\n",
    "    return acc#方便取最优模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- debug技巧\n",
    "\n",
    "    - 十类，每一类概率都是0.1，根据loss的初始化，初始值应该是log10，所以可以判断最开始的loss是2.3是否合适\n",
    "    - 如果反复运行训练两个epochs，loss会不断优化，第一次迭代的loss就在上一次结果的loss优化，准确率越来越高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302585092994046"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  模型保存和加载及打印参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_epoch:0，iteration：0，loss:2.30064,\n",
      "train_epoch:0，iteration：100，loss:2.21395,\n",
      "train_epoch:0，iteration：200，loss:0.85474,\n",
      "train_epoch:0，iteration：300，loss:0.60452,\n",
      "train_epoch:0，iteration：400，loss:0.39538,\n",
      "train_epoch:0，iteration：500，loss:0.21170,\n",
      "train_epoch:0，iteration：600，loss:0.50295,\n",
      "train_epoch:0，iteration：700，loss:0.13989,\n",
      "train_epoch:0，iteration：800，loss:0.51564,\n",
      "train_epoch:0，iteration：900，loss:0.22044,\n",
      "test_loss:0.00276，准确率:0.94810\n",
      "train_epoch:1，iteration：0，loss:0.16161,\n",
      "train_epoch:1，iteration：100，loss:0.14594,\n",
      "train_epoch:1，iteration：200，loss:0.20588,\n",
      "train_epoch:1，iteration：300，loss:0.07314,\n",
      "train_epoch:1，iteration：400，loss:0.11452,\n",
      "train_epoch:1，iteration：500，loss:0.07849,\n",
      "train_epoch:1，iteration：600，loss:0.12429,\n",
      "train_epoch:1，iteration：700，loss:0.21019,\n",
      "train_epoch:1，iteration：800，loss:0.09245,\n",
      "train_epoch:1，iteration：900，loss:0.14659,\n",
      "test_loss:0.00155，准确率:0.96850\n"
     ]
    }
   ],
   "source": [
    "# torch.save(model.state_dict(),\"mnist_cnn.pth\") # 只保存神经网络的模型参数   \n",
    "#t保存最优模型\n",
    "num_epochs= 2\n",
    "best_valid_acc = 0.\n",
    "for epoch in range(num_epochs):\n",
    "    Train(mnist_model,mnist_train_dataloader,Loss_fn,optimizer,epoch)\n",
    "    acc = Test(mnist_model,mnist_test_dataloader,Loss_fn)\n",
    "    if acc > best_valid_acc:\n",
    "        best_valid_acc = acc\n",
    "        torch.save(mnist_model.state_dict(),\"best_mnist_cnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([20, 1, 5, 5])\n",
      "conv1.bias \t torch.Size([20])\n",
      "conv2.weight \t torch.Size([50, 20, 5, 5])\n",
      "conv2.bias \t torch.Size([50])\n",
      "fc1.weight \t torch.Size([500, 800])\n",
      "fc1.bias \t torch.Size([500])\n",
      "fc2.weight \t torch.Size([10, 500])\n",
      "fc2.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {1767310573304: {'momentum_buffer': tensor([[[[-8.2635e-03, -1.4580e-02, -1.7740e-02, -1.9181e-02, -2.1253e-02],\n",
      "          [-7.0006e-03, -1.2943e-02, -1.5249e-02, -1.9282e-02, -2.1084e-02],\n",
      "          [-4.2616e-03, -8.7391e-03, -9.9263e-03, -1.1852e-02, -1.6189e-02],\n",
      "          [-4.3360e-03, -3.4405e-03, -4.4456e-03, -7.9326e-03, -1.7687e-02],\n",
      "          [ 7.3884e-04,  1.0026e-03, -4.0219e-03, -1.2944e-02, -2.0509e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0375e-03,  3.0989e-03, -1.8878e-04, -2.6025e-03, -1.7005e-03],\n",
      "          [ 2.9432e-03,  1.5412e-03, -2.1823e-03, -4.0925e-03, -5.3510e-03],\n",
      "          [ 3.4433e-03,  1.3687e-03, -5.4327e-03, -1.0017e-02, -9.5813e-03],\n",
      "          [ 1.0118e-03, -1.7004e-03, -6.5621e-03, -8.1844e-03, -5.6584e-03],\n",
      "          [ 2.1767e-03, -1.9289e-03, -3.7934e-03, -3.5685e-03, -2.4711e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.1095e-03, -1.2068e-02, -1.4474e-02, -1.3381e-02, -1.3263e-02],\n",
      "          [-8.0261e-03, -9.5720e-03, -9.1070e-03, -8.8069e-03, -9.0552e-03],\n",
      "          [-4.8024e-03, -5.2782e-03, -3.9298e-03, -2.9583e-03, -6.3861e-03],\n",
      "          [-5.8883e-03, -6.0848e-03, -4.9506e-03, -3.1751e-03, -6.3934e-03],\n",
      "          [-9.2213e-03, -1.0056e-02, -9.4232e-03, -8.3902e-03, -8.8409e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9514e-03,  2.4384e-03,  1.4969e-03,  5.3531e-03,  2.5509e-03],\n",
      "          [ 2.2963e-03,  1.7547e-03,  4.6249e-03,  4.0065e-03, -3.6907e-04],\n",
      "          [ 3.8696e-03,  6.7752e-04,  4.8831e-05,  1.9724e-03,  1.8113e-04],\n",
      "          [ 4.6924e-03,  3.8237e-03,  5.0710e-03,  3.9330e-03,  1.7253e-03],\n",
      "          [ 5.8110e-03,  5.2096e-03,  5.6058e-03,  3.6402e-03,  2.5404e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0816e-04,  8.0915e-03,  1.4743e-02,  1.5082e-02,  5.3919e-03],\n",
      "          [ 6.9675e-03,  1.0393e-02,  6.5492e-03,  1.5556e-03, -8.0304e-03],\n",
      "          [ 5.1559e-04, -1.0492e-03, -5.1721e-03, -7.8056e-03, -1.1381e-02],\n",
      "          [-2.1199e-03, -5.5588e-03, -4.5828e-03, -6.1346e-03, -7.8124e-03],\n",
      "          [ 6.5618e-03,  1.8211e-03,  6.5515e-04, -3.2323e-03, -9.7261e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1096e-03,  5.5548e-03,  7.9205e-03,  8.1403e-03,  5.2100e-03],\n",
      "          [-1.7256e-04,  1.9804e-03,  2.0221e-03, -1.3343e-03, -2.7850e-03],\n",
      "          [-2.0392e-03, -3.7879e-03, -2.1046e-03, -4.3891e-03, -5.0665e-03],\n",
      "          [ 6.7254e-04,  1.0070e-03,  2.6167e-03, -9.5424e-04, -2.6622e-03],\n",
      "          [ 5.3507e-03,  4.1763e-03,  3.6082e-03, -7.8715e-04, -3.3157e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3921e-03,  4.4894e-03,  3.2151e-03,  1.1508e-04, -4.6519e-04],\n",
      "          [ 4.0300e-03,  2.5162e-03,  2.0538e-03, -3.9529e-04, -1.7290e-03],\n",
      "          [ 3.1979e-03,  3.2149e-04, -1.2003e-04, -1.2051e-03, -1.6338e-03],\n",
      "          [ 2.3092e-03,  9.2857e-04,  1.0843e-03,  8.5365e-04,  4.6716e-04],\n",
      "          [ 3.3193e-03,  4.2449e-03,  4.9672e-03,  2.9517e-03,  3.1770e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2295e-03,  1.2483e-02,  1.9415e-02,  2.0533e-02,  1.3188e-02],\n",
      "          [ 5.3816e-03,  1.2393e-02,  1.4293e-02,  6.5287e-03,  3.9019e-03],\n",
      "          [ 5.0106e-03,  4.2731e-03, -6.6114e-06, -4.9802e-03, -6.3406e-03],\n",
      "          [ 3.9719e-03,  3.3019e-03,  4.6815e-03, -2.5681e-03, -2.8512e-03],\n",
      "          [ 1.0621e-02,  1.2618e-02,  9.9973e-03,  3.6888e-03, -2.9718e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3691e-02,  2.3631e-02,  2.3394e-02,  1.7012e-02,  2.5574e-03],\n",
      "          [ 1.4600e-02,  2.1665e-02,  1.8800e-02,  9.9874e-03,  1.7785e-04],\n",
      "          [ 1.9078e-02,  1.8629e-02,  1.4048e-02,  5.1341e-03, -1.2990e-03],\n",
      "          [ 1.9022e-02,  1.8670e-02,  1.5937e-02,  9.6505e-03,  2.8393e-03],\n",
      "          [ 1.2740e-02,  1.1471e-02,  1.2102e-02,  4.3279e-03, -3.8989e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3153e-04,  1.3864e-02,  2.3485e-02,  2.2217e-02,  9.3532e-03],\n",
      "          [ 1.3580e-03,  1.2520e-02,  1.9242e-02,  1.1594e-02,  2.1972e-03],\n",
      "          [ 1.2061e-02,  1.1119e-02,  1.2619e-02,  5.1338e-03, -2.5087e-03],\n",
      "          [ 1.6489e-02,  1.6549e-02,  2.1849e-02,  1.1345e-02,  1.7955e-03],\n",
      "          [ 2.2605e-02,  1.8596e-02,  2.2776e-02,  1.2502e-02, -8.7417e-04]]],\n",
      "\n",
      "\n",
      "        [[[-4.1984e-03, -2.6299e-03, -2.5167e-03, -4.4809e-03, -2.5117e-03],\n",
      "          [-4.7500e-04,  4.9735e-04, -1.8461e-03, -3.5062e-03, -4.1076e-03],\n",
      "          [-1.0127e-03, -6.6906e-04, -3.2477e-03, -3.8839e-03, -2.9208e-03],\n",
      "          [-4.1670e-03, -2.3630e-03, -2.3286e-03, -2.2362e-03,  8.6716e-05],\n",
      "          [-4.2761e-03, -8.4452e-04, -1.9855e-03, -1.4194e-03,  1.2530e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6960e-03,  4.0791e-03,  1.3573e-03,  1.5241e-03, -1.8217e-03],\n",
      "          [ 7.6464e-03,  2.9308e-03,  1.0690e-03,  1.3127e-03, -1.7500e-03],\n",
      "          [ 7.8582e-03,  3.5133e-03,  1.9032e-03,  1.6288e-04, -2.3815e-03],\n",
      "          [ 9.2606e-03,  5.9597e-03,  2.2897e-03, -1.1398e-03, -3.4857e-03],\n",
      "          [ 8.6181e-03,  5.5928e-03,  2.6531e-03, -3.5824e-04, -3.7221e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6700e-04,  3.9868e-04,  5.0068e-05,  8.4787e-04,  2.5353e-04],\n",
      "          [ 3.4504e-04,  1.2361e-03,  5.6605e-04,  3.4901e-04,  2.9701e-04],\n",
      "          [ 6.6480e-04,  1.2611e-03,  7.1000e-04,  1.0854e-04,  2.1995e-05],\n",
      "          [ 8.1259e-04,  6.1937e-04,  5.1639e-04,  3.3918e-04,  1.2875e-05],\n",
      "          [ 5.0029e-04,  3.7346e-04,  4.5251e-04,  7.1518e-05,  2.7975e-04]]],\n",
      "\n",
      "\n",
      "        [[[-9.7861e-03, -1.9026e-02, -2.1171e-02, -2.0808e-02, -1.9524e-02],\n",
      "          [-1.1431e-02, -1.7371e-02, -1.3007e-02, -1.7425e-02, -1.8620e-02],\n",
      "          [-2.1691e-03, -6.8987e-03, -9.7596e-03, -1.6464e-02, -1.9193e-02],\n",
      "          [ 6.5038e-03,  9.2879e-04, -4.7589e-03, -1.2640e-02, -1.5744e-02],\n",
      "          [ 3.3516e-03, -1.6359e-03, -8.3964e-03, -1.4207e-02, -1.5903e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.3379e-04,  1.6762e-03,  4.7591e-03,  7.9079e-03,  5.7271e-03],\n",
      "          [ 3.5943e-03,  4.7438e-03,  6.4433e-03,  6.8886e-03,  3.3961e-03],\n",
      "          [ 3.9028e-03,  3.3907e-03,  1.2245e-03,  5.1963e-04, -4.8140e-04],\n",
      "          [ 7.2053e-06, -7.7754e-05, -1.2598e-03, -1.1484e-03,  1.1682e-03],\n",
      "          [-1.1268e-03, -4.6170e-04, -1.1250e-03,  3.6625e-04,  2.7153e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.2716e-03, -3.9016e-03, -1.1600e-03,  9.9661e-04,  3.2039e-03],\n",
      "          [-3.6851e-03, -2.4683e-03, -9.0047e-04,  1.9954e-03,  3.0004e-03],\n",
      "          [-1.8184e-03, -2.0339e-03, -8.9424e-04, -1.6894e-03,  1.6228e-05],\n",
      "          [-2.1118e-03, -1.8324e-03, -2.2409e-03, -1.4875e-03, -5.3782e-04],\n",
      "          [-1.1038e-03, -3.5613e-03, -4.2836e-03, -3.3454e-03, -2.1367e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9879e-04,  9.8124e-05, -3.6639e-03, -8.1921e-03, -1.1427e-02],\n",
      "          [-4.9087e-03, -7.3280e-03, -6.7379e-03, -1.1105e-02, -1.0760e-02],\n",
      "          [-4.0215e-03, -5.3035e-03, -3.3001e-03, -7.3346e-03, -8.0387e-03],\n",
      "          [ 9.2166e-04,  2.4302e-03,  1.8100e-03, -2.0805e-03, -4.4120e-03],\n",
      "          [ 3.6788e-03,  4.1117e-03, -4.1157e-06, -2.9444e-03, -3.6243e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.8784e-03, -9.2164e-03, -9.4796e-03, -1.2506e-02, -1.3776e-02],\n",
      "          [-4.0428e-03, -1.1824e-02, -1.4913e-02, -1.8011e-02, -1.6165e-02],\n",
      "          [ 5.7735e-04, -9.3488e-03, -1.2161e-02, -1.3935e-02, -1.5584e-02],\n",
      "          [ 6.6331e-03, -1.3298e-03, -4.7087e-03, -7.2214e-03, -9.9330e-03],\n",
      "          [ 6.0663e-03, -1.5035e-03, -6.2750e-03, -1.0325e-02, -1.0874e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5100e-02, -1.8030e-02, -2.7516e-02, -3.6087e-02, -3.5392e-02],\n",
      "          [-1.6217e-02, -2.1409e-02, -2.8197e-02, -3.8265e-02, -3.7117e-02],\n",
      "          [-7.5032e-03, -1.2956e-02, -1.7805e-02, -2.8881e-02, -3.1785e-02],\n",
      "          [-5.4631e-03, -5.5968e-03, -1.1979e-02, -1.9853e-02, -2.7465e-02],\n",
      "          [ 9.0084e-04, -4.9275e-03, -1.4367e-02, -2.6061e-02, -2.7633e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1143e-03, -3.6465e-03, -1.8426e-03,  3.6345e-03,  7.1021e-03],\n",
      "          [-3.5160e-03, -2.3024e-03,  1.6995e-03,  5.7152e-03,  5.8759e-03],\n",
      "          [-1.4254e-03,  1.2367e-03,  2.9645e-03,  3.6188e-03,  2.3782e-03],\n",
      "          [ 1.1593e-04, -1.9924e-03, -2.1401e-03, -2.0556e-03, -9.2215e-04],\n",
      "          [-8.9611e-04, -2.9156e-03,  2.0902e-04,  9.6501e-05, -1.0423e-03]]]],\n",
      "       device='cuda:0')}, 1767310573464: {'momentum_buffer': tensor([-0.0262,  0.0021, -0.0201,  0.0141, -0.0055, -0.0006,  0.0102,  0.0073,\n",
      "         0.0173,  0.0182, -0.0080,  0.0067,  0.0003, -0.0193,  0.0023,  0.0014,\n",
      "        -0.0072, -0.0173, -0.0584, -0.0016], device='cuda:0')}, 1767310572504: {'momentum_buffer': tensor([[[[-1.5489e-05, -2.4032e-04, -8.6094e-04, -7.3110e-04, -6.8916e-04],\n",
      "          [-3.3867e-05, -8.3996e-04, -1.4444e-03, -1.0049e-03, -5.3214e-04],\n",
      "          [-2.6623e-03, -6.5224e-04, -5.1459e-04, -5.6381e-04, -2.8816e-04],\n",
      "          [-1.5134e-03, -5.5574e-04, -2.4326e-04, -3.0217e-04, -1.4970e-04],\n",
      "          [-1.7196e-03, -1.3261e-03, -5.6832e-04, -3.5647e-04, -2.6637e-05]],\n",
      "\n",
      "         [[-3.5026e-04,  1.3609e-04, -1.4281e-04,  5.4849e-06, -3.1484e-04],\n",
      "          [ 9.9771e-05, -3.1692e-04, -6.7124e-04, -2.1909e-04, -6.3249e-05],\n",
      "          [-9.2175e-04, -3.6536e-04, -6.6315e-04, -2.0974e-04,  9.4384e-05],\n",
      "          [-2.9188e-05,  9.9507e-05, -7.1724e-04, -2.1291e-04,  1.2617e-04],\n",
      "          [-2.4586e-04, -9.9778e-05, -8.1877e-04, -1.5495e-04,  4.9888e-05]],\n",
      "\n",
      "         [[-5.4702e-04, -3.4327e-04, -2.2492e-04, -1.2479e-04, -9.9344e-05],\n",
      "          [ 2.1636e-04, -3.6084e-04, -9.9933e-05, -8.0134e-05, -1.4494e-04],\n",
      "          [-3.1711e-04, -2.1759e-04, -2.2085e-04, -9.5734e-05, -2.5425e-05],\n",
      "          [-2.3235e-04, -1.0847e-04, -1.0779e-04, -3.8714e-05,  1.7279e-05],\n",
      "          [-2.1286e-04, -1.3671e-04, -2.7750e-05, -9.5424e-05, -1.2096e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2291e-04, -2.1148e-04, -9.9319e-04, -9.4562e-04, -6.8774e-04],\n",
      "          [-1.6855e-03, -7.8329e-04, -1.3652e-03, -1.1202e-03, -8.2545e-04],\n",
      "          [-1.7855e-03, -1.2974e-03, -5.8310e-04, -5.2137e-04, -3.9950e-04],\n",
      "          [-1.5030e-03, -1.2584e-03, -7.6815e-04, -3.6108e-04, -4.0301e-04],\n",
      "          [-6.9436e-04, -1.4061e-03, -1.2425e-03, -3.8361e-04, -4.4375e-04]],\n",
      "\n",
      "         [[ 6.4325e-04, -2.1143e-04, -1.1576e-03, -1.0876e-03, -8.6994e-04],\n",
      "          [-9.8393e-04, -1.4897e-03, -1.6063e-03, -1.3658e-03, -7.6565e-04],\n",
      "          [-2.2671e-03, -4.2039e-04, -4.1522e-04, -8.1386e-04, -3.7228e-04],\n",
      "          [-2.1854e-03, -1.7469e-04,  2.3888e-04, -4.2941e-04, -3.7133e-04],\n",
      "          [-7.4979e-04, -9.5080e-04, -3.7808e-04, -5.7143e-04, -4.7252e-04]],\n",
      "\n",
      "         [[-1.9065e-03, -1.0835e-03, -8.9859e-04, -5.9118e-04, -3.3247e-04],\n",
      "          [-1.0968e-03, -6.9822e-04, -1.3379e-04, -4.4066e-04, -2.7334e-04],\n",
      "          [-1.1720e-03, -6.3495e-04, -2.4968e-04, -4.8306e-04, -4.5728e-04],\n",
      "          [-1.6034e-03, -1.0923e-03, -4.6600e-04, -6.4923e-04, -4.8531e-04],\n",
      "          [-1.6818e-03, -9.8328e-04, -2.5997e-04, -6.2696e-04, -5.2955e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5220e-03,  6.5306e-04, -2.0867e-03, -5.8978e-03, -7.5228e-03],\n",
      "          [-1.7970e-03, -2.2649e-03, -4.2868e-03, -6.0401e-03, -8.5226e-03],\n",
      "          [-8.1447e-03, -7.0194e-03, -5.6156e-03, -4.3260e-03, -4.1297e-03],\n",
      "          [-1.0535e-02, -1.0396e-02, -8.5352e-03, -3.2502e-03, -2.4537e-03],\n",
      "          [-1.8690e-03, -5.6318e-03, -9.4831e-03, -9.2200e-03, -4.1487e-03]],\n",
      "\n",
      "         [[ 2.2957e-04, -2.3239e-04, -2.6279e-03, -1.7255e-03, -1.2934e-03],\n",
      "          [-2.0053e-03, -8.9665e-04, -1.5076e-03,  4.2336e-04, -1.3800e-03],\n",
      "          [-1.2208e-03, -2.3510e-03, -3.2864e-03, -8.5352e-04, -1.3150e-03],\n",
      "          [ 4.8580e-05, -3.1948e-03, -1.8205e-03,  1.0259e-03, -3.2974e-03],\n",
      "          [ 6.1442e-04, -1.5574e-03, -1.3519e-03, -1.1570e-03, -1.8953e-03]],\n",
      "\n",
      "         [[-1.4662e-03, -1.6547e-03, -1.4094e-03, -1.6529e-04, -7.3867e-04],\n",
      "          [-1.1517e-04, -5.7816e-04, -2.4908e-03, -2.2945e-03, -1.7143e-03],\n",
      "          [-8.4810e-04, -1.4095e-03, -8.0407e-04, -1.0422e-03, -1.3960e-03],\n",
      "          [-6.5051e-04, -1.6069e-03, -1.9426e-04, -2.8516e-04, -7.0944e-04],\n",
      "          [-1.9209e-03, -1.5432e-03, -1.5340e-03,  1.3649e-04,  2.7442e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3247e-03,  7.4662e-04, -1.1735e-03, -6.7141e-03, -8.7962e-03],\n",
      "          [-3.9927e-03, -4.9091e-03, -3.5874e-03, -6.6783e-03, -6.1932e-03],\n",
      "          [-7.7587e-03, -6.6870e-03, -6.4968e-03, -4.0650e-03, -4.3018e-03],\n",
      "          [-1.0612e-02, -1.0670e-02, -7.9919e-03, -5.2042e-03, -2.8459e-03],\n",
      "          [-2.1831e-03, -2.3510e-03, -3.9793e-03, -7.7839e-03, -6.2409e-03]],\n",
      "\n",
      "         [[ 2.3842e-03,  2.1827e-03, -6.3261e-04, -7.5163e-03, -1.0356e-02],\n",
      "          [-2.6848e-03, -1.4038e-03, -6.4214e-03, -9.1822e-03, -6.7935e-03],\n",
      "          [-7.9546e-03, -5.1940e-03, -4.6276e-03, -5.5989e-03, -3.9577e-03],\n",
      "          [-1.4611e-02, -1.4716e-02, -1.1582e-02, -2.9860e-03,  1.4085e-04],\n",
      "          [-3.6933e-03, -4.7502e-03, -9.5300e-03, -1.0451e-02, -6.0083e-03]],\n",
      "\n",
      "         [[-6.6384e-03, -5.3608e-03, -4.3741e-03, -4.9845e-03, -2.3988e-03],\n",
      "          [-6.4420e-03, -5.3176e-03, -2.9340e-03, -3.6705e-03, -1.1769e-03],\n",
      "          [-3.7772e-03, -1.9898e-03, -3.8601e-03, -3.7901e-03, -1.7438e-03],\n",
      "          [ 8.7963e-04,  1.6463e-03, -3.2963e-03, -4.4761e-03, -3.0753e-03],\n",
      "          [-4.6964e-04,  7.7699e-05, -1.6957e-03, -1.9165e-03, -3.0500e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1023e-03,  5.9368e-03,  1.1703e-02,  1.5100e-02,  1.8169e-02],\n",
      "          [ 1.4356e-02,  1.5250e-02,  1.2840e-02,  1.2067e-02,  1.4821e-02],\n",
      "          [ 1.3869e-02,  1.5359e-02,  1.1572e-02,  8.2107e-03,  9.2078e-03],\n",
      "          [ 5.8111e-03,  7.7128e-03,  4.9536e-03,  3.1046e-03,  5.9475e-03],\n",
      "          [ 5.8927e-03,  1.1059e-02,  1.0135e-02,  9.0863e-03,  1.0371e-02]],\n",
      "\n",
      "         [[ 2.2371e-03,  9.4558e-04,  3.4258e-03,  4.2752e-03,  5.4994e-03],\n",
      "          [ 1.7173e-03,  2.8104e-03,  4.3114e-03,  2.7627e-03,  3.7950e-03],\n",
      "          [ 4.6746e-04,  1.5863e-03,  1.7445e-03,  1.4377e-03,  1.9189e-03],\n",
      "          [ 3.7145e-04,  1.5375e-03,  7.6949e-04,  2.3611e-03,  1.8635e-03],\n",
      "          [ 3.8633e-04,  3.0491e-03,  6.8129e-04,  2.9846e-03,  2.3636e-03]],\n",
      "\n",
      "         [[-1.1424e-04,  1.6808e-03,  4.0858e-03,  3.5044e-03,  2.6682e-03],\n",
      "          [ 5.2894e-04,  1.1779e-03,  2.0925e-03,  2.6766e-03,  2.8214e-03],\n",
      "          [ 2.2409e-03,  3.3242e-03,  3.4660e-03,  2.3633e-03,  2.0641e-03],\n",
      "          [ 2.0519e-04,  9.7649e-04,  8.7739e-04,  9.1720e-04,  1.2348e-03],\n",
      "          [ 8.1035e-04,  9.0815e-04,  1.8536e-04,  6.3335e-04,  6.1682e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2694e-03,  6.9175e-03,  1.0173e-02,  1.3336e-02,  1.5411e-02],\n",
      "          [ 1.1847e-02,  1.6977e-02,  1.6038e-02,  1.2865e-02,  1.1125e-02],\n",
      "          [ 7.8136e-03,  1.1570e-02,  1.0865e-02,  6.9503e-03,  4.9324e-03],\n",
      "          [ 4.5594e-03,  6.8023e-03,  6.4471e-03,  4.5640e-03,  4.6360e-03],\n",
      "          [ 4.3715e-03,  9.0185e-03,  1.1669e-02,  1.0201e-02,  1.0225e-02]],\n",
      "\n",
      "         [[ 3.0748e-03,  3.5493e-03,  1.0722e-02,  1.6772e-02,  2.0050e-02],\n",
      "          [ 1.8419e-02,  1.8553e-02,  1.7153e-02,  1.6409e-02,  1.6935e-02],\n",
      "          [ 1.7399e-02,  1.6974e-02,  1.3871e-02,  9.6065e-03,  8.9443e-03],\n",
      "          [ 9.6899e-03,  9.2435e-03,  5.0375e-03,  1.9732e-03,  4.1914e-03],\n",
      "          [ 8.3178e-03,  1.3971e-02,  1.3559e-02,  1.0004e-02,  1.1474e-02]],\n",
      "\n",
      "         [[ 1.0709e-02,  9.2277e-03,  6.6221e-03,  4.2817e-03,  4.9208e-03],\n",
      "          [ 5.6755e-03,  3.7454e-03,  2.0101e-03,  9.5418e-04,  2.5609e-03],\n",
      "          [ 3.9993e-03,  4.0171e-03,  3.4719e-03,  3.7670e-03,  5.7152e-03],\n",
      "          [ 3.4631e-03,  5.5382e-03,  6.7012e-03,  6.7774e-03,  8.5791e-03],\n",
      "          [ 1.3594e-03,  1.5947e-03,  3.6784e-03,  3.9264e-03,  6.9173e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.0692e-03,  1.9966e-04, -2.1493e-03, -1.6987e-03, -5.4705e-03],\n",
      "          [ 1.3661e-03, -1.0577e-03, -2.6032e-03, -2.3741e-03, -8.8456e-04],\n",
      "          [-5.4168e-04, -1.1368e-03, -1.3373e-03, -3.8235e-03, -6.2223e-03],\n",
      "          [ 1.8188e-03,  1.1376e-04, -2.6159e-03, -7.0009e-03, -6.2674e-03],\n",
      "          [-1.6140e-04,  1.9578e-03,  6.7395e-04, -4.1372e-03, -7.4913e-03]],\n",
      "\n",
      "         [[-1.1086e-03, -3.9201e-04,  9.6773e-04,  5.7411e-04, -1.5143e-03],\n",
      "          [ 1.2092e-03,  1.7956e-04,  6.4360e-04, -7.5922e-04,  1.2504e-04],\n",
      "          [-5.1874e-04, -1.1420e-03,  2.1840e-03,  7.8852e-04, -1.1976e-03],\n",
      "          [-7.6395e-04,  2.0116e-03,  2.7773e-04, -5.6501e-04,  1.3980e-03],\n",
      "          [-7.1515e-04,  3.2766e-03,  9.4470e-04,  1.1797e-04, -1.3155e-03]],\n",
      "\n",
      "         [[ 7.4314e-04,  1.5600e-04, -1.2309e-03, -9.7675e-04, -4.1564e-04],\n",
      "          [-6.0214e-04, -1.1721e-03, -7.9264e-04, -7.8083e-04, -2.7353e-04],\n",
      "          [-1.5389e-04,  2.1131e-04, -2.8885e-04, -7.5824e-04,  7.0118e-04],\n",
      "          [-5.8316e-04,  1.7116e-04,  2.6212e-04,  9.7498e-04,  8.1028e-04],\n",
      "          [ 3.7135e-04,  1.0953e-03, -4.5436e-04, -8.8971e-04, -7.0405e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7027e-03,  1.0920e-03, -1.1291e-03, -2.5173e-03, -1.4777e-03],\n",
      "          [-8.8949e-04, -1.0040e-03, -2.0200e-03, -1.8556e-03, -1.9613e-03],\n",
      "          [-1.5866e-03, -1.6788e-03, -9.1590e-04, -1.4409e-03, -3.4931e-03],\n",
      "          [-8.6080e-04,  1.2243e-03,  1.1115e-03, -4.2229e-03, -5.5546e-03],\n",
      "          [ 1.2214e-03,  1.6503e-03,  2.6648e-03, -3.9688e-04, -3.6503e-03]],\n",
      "\n",
      "         [[ 4.5541e-03, -2.0731e-03, -5.8877e-03, -3.1580e-03, -3.5078e-03],\n",
      "          [-1.1569e-04, -2.9055e-03, -3.1205e-03, -2.3400e-03,  6.6463e-04],\n",
      "          [-2.8460e-04, -3.6423e-03, -1.7875e-03, -2.6422e-03, -2.9322e-03],\n",
      "          [-2.6142e-03, -9.2705e-04, -2.3242e-03, -7.8581e-03, -8.3197e-03],\n",
      "          [-2.3476e-03, -4.3792e-04,  1.9052e-03, -1.6682e-03, -5.3345e-03]],\n",
      "\n",
      "         [[-4.0121e-04, -1.5476e-03, -9.6432e-04, -2.4073e-03, -5.7222e-04],\n",
      "          [ 6.4878e-04, -1.1994e-03, -1.4813e-03, -2.2563e-03, -2.8893e-03],\n",
      "          [ 1.3943e-03,  9.2455e-04, -1.5251e-03, -3.5753e-03, -2.7304e-03],\n",
      "          [ 2.2179e-03,  5.6779e-05,  5.2708e-04, -7.2793e-04, -5.2307e-04],\n",
      "          [ 1.3947e-03, -2.1989e-03, -2.7202e-03, -1.9637e-03, -2.5514e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.0142e-02, -9.7118e-03, -1.1657e-02, -1.3931e-02, -1.2363e-02],\n",
      "          [-1.0150e-02, -1.1797e-02, -1.2447e-02, -1.2701e-02, -8.3941e-03],\n",
      "          [-6.4030e-03, -5.0777e-03, -6.1742e-03, -7.8469e-03, -7.5030e-03],\n",
      "          [ 1.1864e-03,  2.6011e-03, -9.0461e-05, -3.9336e-03, -5.9296e-03],\n",
      "          [-3.1525e-03, -2.8041e-03, -5.8540e-03, -8.4948e-03, -9.4600e-03]],\n",
      "\n",
      "         [[-3.4675e-03, -3.4254e-03, -3.0117e-03, -2.9343e-04, -2.9613e-03],\n",
      "          [-2.2315e-03, -2.7615e-04, -3.4111e-03, -1.5535e-03, -1.8330e-04],\n",
      "          [-2.7650e-04,  4.1283e-04, -4.4125e-04,  1.1543e-03, -8.1573e-04],\n",
      "          [-1.5052e-04, -6.9750e-04, -1.2627e-03,  2.7169e-04, -2.6498e-03],\n",
      "          [-1.8607e-03, -2.1651e-03, -2.2457e-03, -1.1210e-04, -3.0046e-03]],\n",
      "\n",
      "         [[-1.6905e-03, -6.7789e-04, -2.0384e-03, -3.6236e-03, -1.8722e-03],\n",
      "          [-1.8735e-03, -1.4755e-03, -1.7650e-03, -7.6427e-04, -6.3125e-04],\n",
      "          [-1.6194e-03, -1.6432e-03, -2.1047e-03, -1.6617e-03, -1.0065e-03],\n",
      "          [-7.6640e-04, -4.0105e-04, -2.8604e-04, -7.1122e-05, -1.3926e-04],\n",
      "          [-9.4624e-05,  5.3256e-05,  5.7810e-05,  1.7067e-04, -9.1116e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.2078e-03, -1.0871e-02, -9.9933e-03, -1.0817e-02, -1.1518e-02],\n",
      "          [-9.0480e-03, -1.2164e-02, -1.0001e-02, -1.0143e-02, -8.7112e-03],\n",
      "          [-4.1000e-03, -5.3847e-03, -2.8997e-03, -4.3211e-03, -6.4102e-03],\n",
      "          [-7.7545e-04,  6.1364e-04,  1.5285e-03, -2.5267e-03, -7.0419e-03],\n",
      "          [-5.9137e-03, -5.6713e-03, -5.6893e-03, -8.5057e-03, -9.3054e-03]],\n",
      "\n",
      "         [[-9.9900e-03, -1.2385e-02, -1.3944e-02, -1.7494e-02, -1.0985e-02],\n",
      "          [-1.4774e-02, -1.6194e-02, -1.6525e-02, -1.6326e-02, -9.6094e-03],\n",
      "          [-7.6696e-03, -7.9783e-03, -7.2006e-03, -9.2607e-03, -3.9863e-03],\n",
      "          [ 1.1513e-03,  2.8864e-03,  1.3449e-03, -3.9556e-03, -3.2863e-03],\n",
      "          [-4.3508e-03, -3.9942e-03, -8.6002e-03, -1.1146e-02, -9.7041e-03]],\n",
      "\n",
      "         [[-5.1910e-03, -3.0762e-03, -2.1642e-03, -6.5180e-03, -3.2522e-03],\n",
      "          [-1.2879e-04,  2.0119e-04,  5.7166e-04, -4.7352e-03, -3.3650e-03],\n",
      "          [-1.2118e-03, -8.7633e-04, -2.8036e-03, -5.7428e-03, -6.1779e-03],\n",
      "          [-4.5670e-03, -4.7691e-03, -6.0631e-03, -7.2086e-03, -5.1292e-03],\n",
      "          [-2.8018e-03, -1.5069e-03, -3.4107e-03, -4.6993e-03, -2.6861e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.7564e-03,  5.2256e-04,  1.1671e-03,  1.6843e-03, -1.5960e-03],\n",
      "          [ 4.5909e-03,  3.6049e-03,  2.2292e-03,  2.0895e-03, -2.2175e-04],\n",
      "          [ 7.9563e-03,  7.4106e-03,  4.8923e-03,  2.6255e-03,  3.2823e-03],\n",
      "          [ 3.2585e-03,  5.8230e-03,  7.6257e-03,  9.8877e-03,  8.1979e-03],\n",
      "          [ 4.6007e-03,  6.9936e-03,  7.2087e-03,  5.2013e-03,  3.9646e-03]],\n",
      "\n",
      "         [[ 5.9430e-04,  5.4660e-04,  5.2561e-04, -4.8384e-04, -3.9742e-04],\n",
      "          [ 1.2508e-03,  2.4086e-04,  1.7993e-03,  7.8495e-04,  4.1851e-04],\n",
      "          [ 7.1839e-04,  1.2737e-03,  2.5368e-03,  9.0492e-04,  2.9507e-03],\n",
      "          [ 5.3572e-04,  1.7155e-03,  2.5589e-03,  2.5800e-03,  2.8184e-03],\n",
      "          [ 2.1921e-03,  3.5153e-03,  2.6910e-03, -2.5858e-04,  1.6978e-03]],\n",
      "\n",
      "         [[-4.0505e-04, -4.2124e-04,  6.4693e-06,  7.8492e-04,  2.7046e-04],\n",
      "          [ 7.6096e-04,  8.5137e-04,  1.1255e-03,  7.5953e-04,  1.1591e-03],\n",
      "          [ 1.3300e-03,  4.3919e-04,  2.9025e-04,  4.4308e-04,  6.3779e-04],\n",
      "          [ 1.7286e-03,  1.5699e-03,  8.8435e-04,  8.5965e-04,  1.1047e-03],\n",
      "          [ 5.5682e-04,  1.0202e-03,  1.5248e-03,  2.2847e-03,  1.9473e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6275e-04,  5.5785e-04,  2.1806e-03,  1.7801e-03,  8.4171e-04],\n",
      "          [ 5.5622e-03,  4.6731e-03,  3.2128e-03,  1.4249e-03,  1.8781e-03],\n",
      "          [ 6.5949e-03,  8.0618e-03,  6.4756e-03,  4.9704e-03,  4.4078e-03],\n",
      "          [ 2.1281e-03,  4.4972e-03,  7.3999e-03,  9.0755e-03,  9.4938e-03],\n",
      "          [ 5.2791e-03,  6.3560e-03,  8.3432e-03,  6.2460e-03,  4.2142e-03]],\n",
      "\n",
      "         [[-2.1265e-03,  1.0092e-03,  2.7137e-03,  2.3831e-03, -1.5237e-03],\n",
      "          [ 5.9590e-03,  3.5459e-03,  1.5267e-03,  8.4604e-04, -4.1124e-04],\n",
      "          [ 1.0469e-02,  7.1512e-03,  5.3681e-03,  2.9145e-03,  1.9278e-03],\n",
      "          [ 2.5140e-03,  3.3781e-03,  5.3936e-03,  1.0073e-02,  1.1005e-02],\n",
      "          [ 3.6559e-03,  5.1561e-03,  7.3226e-03,  7.7727e-03,  4.3311e-03]],\n",
      "\n",
      "         [[ 5.0276e-03,  3.2198e-03,  2.7620e-03,  2.8328e-03,  3.2055e-03],\n",
      "          [ 4.3086e-03,  5.7329e-03,  5.6803e-03,  6.0685e-03,  5.4258e-03],\n",
      "          [ 4.5180e-03,  4.7112e-03,  5.6276e-03,  4.8238e-03,  3.8220e-03],\n",
      "          [ 6.7641e-03,  4.8764e-03,  3.9253e-03,  9.9355e-04, -1.0947e-04],\n",
      "          [ 6.5334e-03,  4.4368e-03,  3.3231e-03,  1.6876e-03,  2.1199e-03]]]],\n",
      "       device='cuda:0')}, 1767310631384: {'momentum_buffer': tensor([-1.9260e-03, -7.4135e-03,  1.2520e-02, -1.0001e-02, -2.1884e-03,\n",
      "         7.6351e-05, -4.8913e-04, -4.3196e-03,  2.1526e-03, -1.3068e-03,\n",
      "         3.8938e-03,  5.2127e-04, -3.7480e-03, -1.3537e-03, -1.1653e-03,\n",
      "         1.9974e-03, -1.5492e-03, -7.3963e-03,  1.0566e-02,  1.8566e-02,\n",
      "         7.2310e-03, -2.5839e-03, -1.4722e-03, -3.6701e-03,  2.1260e-03,\n",
      "         8.4572e-03,  1.0220e-02, -2.6098e-04, -4.7592e-03,  1.2356e-03,\n",
      "        -3.3236e-03, -9.0176e-03,  3.1011e-03, -4.8470e-03, -1.6207e-03,\n",
      "         3.7816e-04,  3.1363e-03,  5.1363e-03,  9.1643e-03,  3.4652e-03,\n",
      "         6.5804e-03,  8.0629e-03,  1.8686e-03,  9.1732e-03, -1.6230e-04,\n",
      "         1.9513e-03, -7.3719e-03, -1.0622e-03, -1.0672e-02,  9.5522e-03],\n",
      "       device='cuda:0')}, 1767310633384: {'momentum_buffer': tensor([[ 3.5085e-10,  9.8141e-08,  1.4883e-08,  ...,  9.0834e-05,\n",
      "          2.1575e-05,  2.0633e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.8472e-06, -2.3378e-06, -4.3672e-04,  ...,  1.8927e-03,\n",
      "          1.0081e-03,  9.2495e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 9.9959e-05,  5.0521e-05,  5.4492e-04,  ...,  4.1147e-03,\n",
      "          2.7622e-03,  4.7354e-04],\n",
      "        [ 1.4240e-06, -1.2197e-05,  9.0733e-05,  ..., -2.6689e-03,\n",
      "         -1.2863e-03, -5.9507e-04]], device='cuda:0')}, 1767310633544: {'momentum_buffer': tensor([ 4.2803e-05,  0.0000e+00,  1.3654e-03, -8.9388e-04, -1.5013e-03,\n",
      "         1.5332e-03,  6.7488e-04, -3.5983e-07,  7.2000e-04,  7.3981e-04,\n",
      "        -7.6692e-05,  6.0453e-04,  8.8508e-04, -4.6246e-03,  1.1524e-03,\n",
      "         2.4113e-06,  6.4762e-04, -3.7322e-03, -2.9079e-04, -6.3443e-04,\n",
      "         2.4777e-05, -2.6033e-03, -1.0411e-03,  6.3320e-04, -3.0127e-03,\n",
      "        -7.5870e-05, -6.8423e-05,  1.8125e-04,  5.3887e-11,  2.0006e-04,\n",
      "        -4.7386e-04, -2.2216e-04,  2.0326e-03, -3.6276e-04,  2.5556e-03,\n",
      "         1.1320e-05,  9.0056e-05, -4.9747e-05,  1.5769e-03, -1.7705e-04,\n",
      "         1.0973e-03, -2.0009e-06,  2.7211e-03,  4.3657e-08,  5.5834e-03,\n",
      "        -1.1769e-04, -1.5928e-03,  1.5875e-03,  3.1190e-03,  2.6983e-04,\n",
      "        -2.5715e-03,  2.2318e-04,  2.6415e-03, -4.1718e-04,  1.8262e-04,\n",
      "         5.0569e-04, -1.4437e-03, -3.4992e-03,  3.6434e-03,  4.8018e-05,\n",
      "         9.4924e-04, -2.6543e-03,  6.0885e-04, -3.8776e-04,  1.5551e-03,\n",
      "        -1.9799e-03,  3.2210e-05,  1.1809e-03, -1.2390e-05,  2.4327e-03,\n",
      "         6.0541e-25, -1.3156e-03, -2.0375e-03,  8.0125e-05,  4.6182e-06,\n",
      "        -4.3426e-05,  1.2124e-03,  1.9259e-03, -3.5106e-03, -6.0412e-04,\n",
      "        -1.5812e-03, -7.9524e-04, -8.7754e-03, -2.0080e-03, -3.5419e-06,\n",
      "         1.9831e-08,  3.0512e-03,  1.8080e-04, -3.3645e-03, -2.7479e-03,\n",
      "         5.7954e-04,  1.4079e-03,  1.2197e-03, -5.1903e-04, -2.5579e-03,\n",
      "         1.4930e-03,  1.6833e-03, -5.2434e-06, -1.1762e-03,  0.0000e+00,\n",
      "         5.9513e-08, -4.5035e-03, -2.0534e-05, -1.7490e-05, -9.2361e-04,\n",
      "        -8.9735e-09,  6.6650e-04,  1.0169e-05, -9.1619e-04,  0.0000e+00,\n",
      "        -8.9682e-06, -3.7720e-03, -1.5267e-04, -3.0180e-04, -1.4467e-04,\n",
      "        -2.6538e-03,  8.6222e-04, -1.2149e-03,  2.6079e-04,  2.7621e-09,\n",
      "         6.3257e-05,  2.8210e-04, -2.6996e-03, -7.7064e-05, -1.2326e-04,\n",
      "         2.5665e-03,  4.7979e-04, -9.1740e-04,  2.3849e-03, -3.8251e-06,\n",
      "         0.0000e+00,  1.6316e-04,  4.2765e-04, -3.2244e-04,  1.5757e-03,\n",
      "        -1.2925e-04,  2.4438e-03, -1.1551e-03, -1.6773e-03, -9.8295e-04,\n",
      "        -4.1745e-03,  4.0533e-05, -9.8355e-04,  3.0406e-10,  3.4477e-06,\n",
      "        -3.5809e-03,  1.7517e-03,  3.4867e-04, -1.2586e-04,  2.9031e-04,\n",
      "         5.3975e-06,  1.5827e-03, -3.3000e-03, -3.7566e-04, -7.1351e-05,\n",
      "        -4.4817e-04,  4.4901e-04,  6.4729e-04,  6.0995e-04,  2.4649e-04,\n",
      "        -6.6700e-22,  9.5534e-05, -1.1324e-03, -6.5090e-04, -2.9507e-04,\n",
      "        -1.3413e-04, -5.1192e-04,  8.3648e-05,  2.2332e-04, -1.3184e-04,\n",
      "        -2.9348e-03, -1.8970e-03,  1.4183e-03, -2.3396e-05,  2.8573e-03,\n",
      "         2.9033e-03, -2.0188e-04, -6.7919e-04, -2.1567e-03, -7.2752e-04,\n",
      "        -1.0309e-03,  1.9182e-03,  3.4796e-04,  2.8676e-03,  0.0000e+00,\n",
      "         8.0039e-04,  2.2180e-07, -6.7943e-04, -1.5430e-03,  5.3736e-04,\n",
      "         3.1838e-04,  4.1043e-03, -4.8404e-04, -3.0395e-03,  1.2224e-03,\n",
      "         1.8679e-05,  7.4126e-04,  1.2085e-04, -5.9700e-04,  4.4542e-03,\n",
      "         7.2985e-05,  3.1564e-05, -1.6431e-04, -3.3712e-03, -1.5812e-03,\n",
      "        -1.5767e-04,  5.7342e-04,  3.4661e-04,  1.6749e-03, -2.0674e-03,\n",
      "         0.0000e+00, -3.3523e-04,  4.0138e-04,  3.6098e-03,  2.3962e-03,\n",
      "         1.5111e-03,  3.4612e-03,  1.8928e-03,  6.7231e-04,  4.3784e-05,\n",
      "        -6.7876e-06,  2.1035e-03,  2.5719e-03, -4.0657e-03, -1.6633e-03,\n",
      "        -2.3211e-03,  1.1738e-05,  3.1099e-07, -5.1611e-04, -2.0130e-03,\n",
      "        -3.2890e-04, -6.3538e-04, -2.3046e-04, -1.1159e-03,  1.2588e-04,\n",
      "         3.3012e-03, -3.2543e-03,  1.2405e-04, -1.6117e-04, -8.1797e-06,\n",
      "         2.5499e-03,  6.0326e-14, -1.0629e-03, -6.0391e-05, -9.8675e-04,\n",
      "         1.9999e-03,  1.6587e-03,  3.5123e-03,  8.3874e-04,  2.5386e-03,\n",
      "        -7.3648e-05,  4.6433e-04, -5.1313e-04, -1.9962e-03,  2.7551e-03,\n",
      "        -3.1225e-04,  1.8556e-03, -2.0127e-04,  2.8076e-04,  6.5920e-04,\n",
      "         2.3905e-03,  1.0347e-03,  1.6056e-04,  1.6900e-05,  1.6509e-03,\n",
      "        -1.0284e-03, -1.9653e-04, -1.7326e-03,  4.1641e-07,  6.1878e-04,\n",
      "        -1.7634e-03, -8.4868e-04, -3.4590e-04, -3.5592e-03,  5.6654e-04,\n",
      "        -5.0807e-04, -1.2338e-04, -2.0372e-03,  2.3958e-04,  1.1410e-03,\n",
      "        -2.6750e-03,  6.5672e-05, -1.8151e-03,  7.3725e-04, -1.5154e-03,\n",
      "         5.0690e-04,  4.6261e-03,  2.1684e-04, -9.7626e-04, -3.7376e-03,\n",
      "        -3.1959e-03, -8.6444e-05,  1.1361e-03, -2.1699e-05, -4.2802e-04,\n",
      "         1.5836e-03, -1.8657e-03,  1.4961e-06, -3.1757e-04,  4.0128e-14,\n",
      "        -2.5754e-04,  4.2264e-14,  3.4584e-04,  9.1725e-06, -3.1017e-03,\n",
      "        -4.9935e-04, -5.8122e-03, -1.0596e-03,  9.5326e-04, -3.3456e-03,\n",
      "        -7.2441e-04, -3.8900e-03,  6.1360e-03,  2.2760e-03,  5.2458e-04,\n",
      "        -2.8272e-03, -3.0173e-05,  1.8587e-03, -6.4654e-04,  2.5731e-03,\n",
      "        -1.9629e-03, -3.7439e-06,  3.6782e-03, -1.3993e-04,  7.0167e-04,\n",
      "        -6.4097e-05,  1.8797e-03, -2.7340e-03,  4.3435e-04, -3.6720e-04,\n",
      "         3.7325e-04, -3.0379e-04, -3.2072e-04, -1.0509e-03, -2.5417e-03,\n",
      "         4.6294e-04,  1.4115e-03,  9.6918e-05,  1.7985e-03, -7.8176e-04,\n",
      "        -8.9465e-04, -1.1527e-03,  2.5550e-05,  1.9094e-03, -1.4672e-03,\n",
      "         1.3823e-04, -9.6130e-04,  1.6048e-03,  1.1917e-03,  5.4303e-04,\n",
      "        -9.3801e-07,  4.3398e-05,  3.1706e-03, -8.3498e-04, -1.9178e-03,\n",
      "         6.3201e-04, -1.2707e-04, -5.9564e-05,  5.9563e-03, -6.8108e-14,\n",
      "        -1.9426e-03,  3.3734e-05, -1.2518e-03,  2.3684e-06,  3.9120e-38,\n",
      "         0.0000e+00,  2.9166e-04,  1.2124e-03, -4.5402e-03,  1.9101e-03,\n",
      "        -4.5617e-04,  1.5699e-03,  1.1325e-04,  0.0000e+00, -7.0643e-05,\n",
      "        -2.6843e-03, -3.0645e-03,  3.1580e-03,  4.0985e-05,  2.2885e-03,\n",
      "        -4.3548e-03, -1.4778e-03, -9.7463e-09,  9.2028e-08, -1.2864e-04,\n",
      "         1.5708e-03, -2.8452e-03,  4.5316e-06,  0.0000e+00, -2.1896e-03,\n",
      "         2.3264e-03, -1.0326e-03,  1.7091e-04, -1.8155e-04, -6.7432e-04,\n",
      "         0.0000e+00,  1.6785e-07,  1.3121e-03,  3.6540e-03,  1.3295e-03,\n",
      "         2.0595e-03,  2.0441e-03,  1.2391e-03,  1.4199e-03,  2.0277e-04,\n",
      "         7.1287e-04,  3.3337e-03, -9.8528e-04, -1.5600e-03,  1.4543e-03,\n",
      "        -1.0319e-03,  5.0771e-04,  4.9890e-04, -1.9711e-03, -6.9316e-03,\n",
      "        -2.0368e-05,  3.8153e-04, -3.8133e-05, -1.5730e-04, -3.8937e-04,\n",
      "        -2.3422e-03, -3.7765e-03, -5.7549e-03, -2.6728e-04, -3.3707e-03,\n",
      "        -5.2371e-04, -8.3945e-04, -1.1006e-03, -3.7313e-03, -1.6044e-03,\n",
      "        -2.4103e-03, -6.7861e-04,  1.5109e-06, -4.6320e-03,  3.6634e-03,\n",
      "        -9.4251e-04,  6.9181e-04,  5.7140e-04,  4.0539e-04, -3.3102e-09,\n",
      "        -3.1896e-04,  5.9968e-04,  2.2549e-04,  3.4193e-03, -5.8338e-04,\n",
      "        -2.1800e-04,  9.7448e-04, -7.3767e-04,  6.3903e-04,  1.5120e-04,\n",
      "         8.5346e-04, -1.1932e-03,  1.3356e-03,  5.2145e-04,  2.9085e-03,\n",
      "         8.9283e-06, -2.6902e-03,  1.2208e-03, -5.2040e-04,  2.7622e-03,\n",
      "        -1.2779e-03, -1.2396e-04, -1.9820e-03, -2.5623e-04, -3.3440e-03,\n",
      "         0.0000e+00,  1.2026e-03,  1.8493e-03,  2.1581e-04, -5.5857e-04,\n",
      "        -6.2011e-04,  1.5659e-03,  3.5876e-04, -9.4625e-05, -7.5870e-04,\n",
      "         9.2139e-07,  1.4716e-05,  1.1244e-03,  2.1586e-03,  6.0908e-04,\n",
      "         7.0686e-06,  4.1732e-04,  4.2369e-08,  2.8012e-03,  1.9149e-04,\n",
      "        -1.1946e-03, -8.4126e-04,  2.0304e-03, -1.5601e-03, -1.6372e-03,\n",
      "        -1.1632e-03, -2.3304e-03, -7.0769e-04,  1.1966e-03, -2.1744e-05,\n",
      "         2.4885e-03, -3.1883e-03,  0.0000e+00,  8.3842e-04, -1.1070e-03],\n",
      "       device='cuda:0')}, 1767310633624: {'momentum_buffer': tensor([[ 9.6404e-06,  0.0000e+00, -2.2074e-04,  ...,  0.0000e+00,\n",
      "          6.2568e-03,  3.1111e-03],\n",
      "        [-2.6168e-07,  0.0000e+00,  6.1838e-04,  ...,  0.0000e+00,\n",
      "          2.3286e-03, -5.9441e-04],\n",
      "        [ 1.3646e-05,  0.0000e+00,  2.1176e-03,  ...,  0.0000e+00,\n",
      "          3.8063e-02,  2.0194e-02],\n",
      "        ...,\n",
      "        [ 6.6552e-08,  0.0000e+00,  1.7423e-02,  ...,  0.0000e+00,\n",
      "          1.5734e-02,  2.9383e-02],\n",
      "        [ 4.0047e-06,  0.0000e+00,  5.8120e-04,  ...,  0.0000e+00,\n",
      "          2.3184e-02,  3.2881e-03],\n",
      "        [ 1.2333e-07,  0.0000e+00, -1.6016e-02,  ...,  0.0000e+00,\n",
      "         -1.6713e-02, -3.3185e-02]], device='cuda:0')}, 1767310633704: {'momentum_buffer': tensor([ 0.0034,  0.0004,  0.0132, -0.0131, -0.0006, -0.0025, -0.0047,  0.0217,\n",
      "         0.0049, -0.0228], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.01, 'momentum': 0.5, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [1767310573304, 1767310573464, 1767310572504, 1767310631384, 1767310633384, 1767310633544, 1767310633624, 1767310633704]}]\n"
     ]
    }
   ],
   "source": [
    "# Print mnist_model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in mnist_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", mnist_model.state_dict()[param_tensor].size())\n",
    "\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:0.00166，准确率:0.96820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9682, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model= Net()## 前面实例化类命名的时候，要避免重复Net=Net()这种，否则后面再实例化时会出错，不认得类Net\n",
    "test_model.load_state_dict(torch.load(\"mnist_cnn.pth\"))\n",
    "test_model= test_model.cuda()  #要在这一步使用cuda,否则模型在GPU，参数就在cpu\n",
    "Test(test_model,mnist_test_dataloader,Loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备train\n",
    "transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize(mean=(0.2860402,),std=(0.3530239,))\n",
    "                   ])\n",
    "fashion_train= datasets.FashionMNIST(\"./fashion_mnist_data\",train=True,transform=transform)\n",
    "fashion_train_dataloader=tud.DataLoader(fashion_train,batch_size=32,shuffle=True)#DataLoader类\n",
    "# 数据准备test\n",
    "fashion_test= datasets.FashionMNIST(\"./fashion_mnist_data\",train=False,transform=transform)\n",
    "fashion_test_dataloader=tud.DataLoader(fashion_test,batch_size=32,shuffle=True)#DataLoader类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_train\n",
    "fashion_train[0][0] .size()#数组，第一维是tensor，第二维标签,可以进行标准化，计算如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x19b7beacc48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = Net()\n",
    "fashion_model = fashion_model.cuda()# 定义Train和Test时就把输入数据放cuda上，所以这里模型也要做cuda\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "lr = 0.01;momentum = 0.5\n",
    "optimizer = optim.SGD(fashion_model.parameters(),lr=lr,momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_epoch:0，iteration：0，loss:2.30442,\n",
      "train_epoch:0，iteration：100，loss:0.78413,\n",
      "train_epoch:0，iteration：200，loss:0.79574,\n",
      "train_epoch:0，iteration：300，loss:0.98147,\n",
      "train_epoch:0，iteration：400，loss:0.70490,\n",
      "train_epoch:0，iteration：500，loss:0.49413,\n",
      "train_epoch:0，iteration：600，loss:0.60802,\n",
      "train_epoch:0，iteration：700，loss:0.60331,\n",
      "train_epoch:0，iteration：800，loss:0.76761,\n",
      "train_epoch:0，iteration：900，loss:0.67921,\n",
      "train_epoch:0，iteration：1000，loss:0.73171,\n",
      "train_epoch:0，iteration：1100，loss:0.29316,\n",
      "train_epoch:0，iteration：1200，loss:0.47057,\n",
      "train_epoch:0，iteration：1300，loss:0.46732,\n",
      "train_epoch:0，iteration：1400，loss:0.57553,\n",
      "train_epoch:0，iteration：1500，loss:0.41564,\n",
      "train_epoch:0，iteration：1600，loss:0.39209,\n",
      "train_epoch:0，iteration：1700，loss:0.44661,\n",
      "train_epoch:0，iteration：1800，loss:0.49080,\n",
      "test_loss:0.01394，准确率:0.83670\n",
      "train_epoch:1，iteration：0，loss:0.35871,\n",
      "train_epoch:1，iteration：100，loss:0.29302,\n",
      "train_epoch:1，iteration：200，loss:0.46073,\n",
      "train_epoch:1，iteration：300，loss:0.37371,\n",
      "train_epoch:1，iteration：400，loss:0.54164,\n",
      "train_epoch:1，iteration：500，loss:0.16411,\n",
      "train_epoch:1，iteration：600，loss:0.52716,\n",
      "train_epoch:1，iteration：700，loss:0.34020,\n",
      "train_epoch:1，iteration：800，loss:0.81538,\n",
      "train_epoch:1，iteration：900，loss:0.27307,\n",
      "train_epoch:1，iteration：1000，loss:0.21908,\n",
      "train_epoch:1，iteration：1100，loss:0.28911,\n",
      "train_epoch:1，iteration：1200，loss:0.32177,\n",
      "train_epoch:1，iteration：1300，loss:0.49527,\n",
      "train_epoch:1，iteration：1400，loss:0.37701,\n",
      "train_epoch:1，iteration：1500，loss:0.33927,\n",
      "train_epoch:1，iteration：1600，loss:0.54289,\n",
      "train_epoch:1，iteration：1700，loss:0.28325,\n",
      "train_epoch:1，iteration：1800，loss:0.44747,\n",
      "test_loss:0.01126，准确率:0.87080\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model = Train(fashion_model,fashion_train_dataloader,loss_fn,optimizer,epoch)\n",
    "    acc = Test(fashion_model,fashion_test_dataloader,loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fashion_model's state_dict:\n",
      "conv1.weight \t torch.Size([20, 1, 5, 5])\n",
      "conv1.bias \t torch.Size([20])\n",
      "conv2.weight \t torch.Size([50, 20, 5, 5])\n",
      "conv2.bias \t torch.Size([50])\n",
      "fc1.weight \t torch.Size([500, 800])\n",
      "fc1.bias \t torch.Size([500])\n",
      "fc2.weight \t torch.Size([10, 500])\n",
      "fc2.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "torch.save(fashion_model.state_dict(),\"fashion_mnist_cnn.pth\")\n",
    "print(\"fashion_model's state_dict:\")\n",
    "for param_tensor in fashion_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", fashion_model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 计算均值和标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.007498455810546875"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 0\n",
    "for a in fashion_train:\n",
    "     y = a[0].numpy().sum().mean()\n",
    "y / len(fashion_train)  #0.2860406029704958\n",
    "#sum = 0\n",
    "#for a in fashion_train:\n",
    "#    sum += a[0].numpy().std()\n",
    "#sum / len(fashion_train) #0.3202489306078603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
